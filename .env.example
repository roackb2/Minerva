# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=

# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-3.5-turbo

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The OpenAI API key to use.
OPENAI_API_KEY="openai-api-key"

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# For generating a connection URI, see https://docs.timescale.com/use-timescale/latest/services/create-a-service
# The PostgreSQL connection string.
PG_CONNECTION_STRING=postgresql://username:password@localhost:5432/minerva

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# E2B_API_KEY key is required to run code interpreter tool. Get it here: https://e2b.dev/docs/getting-started/api-key
# E2B_API_KEY=

# The system prompt for the AI model.
SYSTEM_PROMPT="You are Minerva, a personal assistant, with access to the user's personal kwowledge base."

# Data to index
DATA_DIRS=`[
  "path/to/first/directory",
  "path/to/second/directory"
]
`"
